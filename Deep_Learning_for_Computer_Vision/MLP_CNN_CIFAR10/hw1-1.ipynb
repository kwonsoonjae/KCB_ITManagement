{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright @ cb_park@korea.ac.kr (Cheonbok Park), joonleesky@kaist.ac.kr (Hojoon Lee)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST Feed-Forward Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn #\n",
    "import torch.nn.functional as F # various activation functions for model\n",
    "import torchvision # You can load various Pretrained Model from this package \n",
    "import torchvision.datasets as vision_dsets\n",
    "import torchvision.transforms as T # Transformation functions to manipulate images\n",
    "import torch.optim as optim # various optimization functions for model\n",
    "from torch.autograd import Variable \n",
    "from torch.utils import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: command not found: wget\n",
      "tar: Error opening archive: Failed to open 'MNIST.tar.gz'\n"
     ]
    }
   ],
   "source": [
    "!wget www.di.ens.fr/~lelarge/MNIST.tar.gz\n",
    "!tar -zxvf MNIST.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initilaize Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MNIST_DATA(root='./',train =True,transforms=None ,download =True,batch_size = 32,num_worker = 1):\n",
    "    print (\"[+] Get the MNIST DATA\")\n",
    "    \"\"\"\n",
    "    We will use Mnist data for our tutorial \n",
    "    \"\"\"\n",
    "    mnist_train = vision_dsets.MNIST(root = root,  #root is the place to store your data. \n",
    "                                    train = True,  \n",
    "                                    transform = T.ToTensor(),\n",
    "                                    download=True)\n",
    "    mnist_test = vision_dsets.MNIST(root = root,\n",
    "                                    train = False, \n",
    "                                    transform = T.ToTensor(),\n",
    "                                    download=True)\n",
    "    \"\"\"\n",
    "    Data Loader is a iterator that fetches the data with the number of desired batch size. \n",
    "    * Practical Guide : What is the optimal batch size? \n",
    "      - Usually.., higher the better. \n",
    "      - We recommend to use it as a multiple of 2 to efficiently utilize the gpu memory. (related to bit size)\n",
    "    \"\"\"\n",
    "    trainDataLoader = data.DataLoader(dataset = mnist_train,  # information about your data type\n",
    "                                      batch_size = batch_size, # batch size\n",
    "                                      shuffle =True, # Whether to shuffle your data for every epoch. (Very important for training performance)\n",
    "                                      num_workers = 1) # number of workers to load your data. (usually number of cpu cores)\n",
    "\n",
    "    testDataLoader = data.DataLoader(dataset = mnist_test, \n",
    "                                    batch_size = batch_size,\n",
    "                                    shuffle = False, # we don't actually need to shuffle data for test\n",
    "                                    num_workers = 1) #\n",
    "    print (\"[+] Finished loading data & Preprocessing\")\n",
    "    return mnist_train,mnist_test,trainDataLoader,testDataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Get the MNIST DATA\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afc7ac18e6a743958afa89aaad77a702",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./MNIST/raw/train-images-idx3-ubyte.gz to ./MNIST/raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db35dcab019a473d80825d95c8c5e76b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./MNIST/raw/train-labels-idx1-ubyte.gz to ./MNIST/raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3171446be7334eee8d4896cbde5ac28d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./MNIST/raw/t10k-images-idx3-ubyte.gz to ./MNIST/raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a24199e52b0b4e09aa60757c1e7be114",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./MNIST/raw/t10k-labels-idx1-ubyte.gz to ./MNIST/raw\n",
      "Processing...\n",
      "Done!\n",
      "[+] Finished loading data & Preprocessing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kwonsoonjae/opt/anaconda3/lib/python3.8/site-packages/torchvision/datasets/mnist.py:480: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ../torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    }
   ],
   "source": [
    "trainDset,testDset,trainDataLoader,testDataLoader= MNIST_DATA(batch_size = 32)  # Data Loader "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer():\n",
    "    def __init__(self, trainloader, testloader, net, optimizer, criterion):\n",
    "        \"\"\"\n",
    "        trainloader: train data's loader\n",
    "        testloader: test data's loader\n",
    "        net: model to train\n",
    "        optimizer: optimizer to update your model\n",
    "        criterion: loss function\n",
    "        \"\"\"\n",
    "        self.trainloader = trainloader\n",
    "        self.testloader = testloader\n",
    "        self.net = net\n",
    "        self.optimizer = optimizer\n",
    "        self.criterion = criterion\n",
    "        \n",
    "    def train(self, epoch = 1):\n",
    "        \"\"\"\n",
    "        epoch: number of times each training sample is used\n",
    "        \"\"\"\n",
    "        self.net.train()\n",
    "        for e in range(epoch):\n",
    "            running_loss = 0.0  \n",
    "            for i, data in enumerate(self.trainloader, 0): \n",
    "                # get the inputs\n",
    "                inputs, labels = data # Return type for data in dataloader is tuple of (input_data, labels)\n",
    "                inputs = inputs#.cuda()\n",
    "                labels = labels#.cuda()\n",
    "                # zero the parameter gradients\n",
    "                self.optimizer.zero_grad()    \n",
    "                #  Question 1) what if we dind't clear up the gradients?\n",
    "\n",
    "                # forward + backward + optimize\n",
    "                outputs = self.net(inputs) # get output after passing through the network\n",
    "                loss = self.criterion(outputs, labels) # compute model's score using the loss function \n",
    "                loss.backward() # perform back-propagation from the loss\n",
    "                self.optimizer.step() # perform gradient descent with given optimizer\n",
    "\n",
    "                # print statistics\n",
    "                running_loss += loss.item()\n",
    "                if (i+1) % 500 == 0:    # print every 2000 mini-batches\n",
    "                    print('[%d, %5d] loss: %.3f' % (e + 1, i + 1, running_loss / 500))\n",
    "                    running_loss = 0.0\n",
    "\n",
    "        print('Finished Training')\n",
    "        \n",
    "    def test(self):\n",
    "        self.net.eval() # Question 2) Why should we change the network into eval-mode?\n",
    "    \n",
    "        test_loss = 0\n",
    "        correct = 0\n",
    "        for inputs, labels in self.testloader:\n",
    "            inputs = inputs#.cuda()\n",
    "            labels = labels#.cuda() \n",
    "            output = self.net(inputs) \n",
    "            pred = output.max(1, keepdim=True)[1] # get the index of the max \n",
    "            correct += pred.eq(labels.view_as(pred)).sum().item()\n",
    "\n",
    "            test_loss /= len(self.testloader.dataset)\n",
    "        print('\\nTest set:  Accuracy: {}/{} ({:.0f}%)\\n'.\n",
    "                format(correct, len(self.testloader.dataset),\n",
    "                100.* correct / len(self.testloader.dataset)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's create Model by yourself"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![activation](./imgs/activation.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exp (1) 2-Layer Network + Sigmoid\n",
    "\n",
    "- Input: (28 * 28)\n",
    "- Hidden dimension: 30\n",
    "- Output dimension: 10\n",
    "- activation: sigmoid\n",
    "- Optimizer: SGD\n",
    "- Loss: Cross-Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNIST_Net(nn.Module): \n",
    "    def __init__(self):\n",
    "        super(MNIST_Net, self).__init__()\n",
    "        # an affine operation: y = Wx + b\n",
    "        self.fc0 = nn.Linear(28*28,30)\n",
    "        self.fc1 = nn.Linear(30, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1,28*28) # x.view convert the shape of tensor, (Batch_size,28,28) --> (Batch_size,28*28)\n",
    "        x = self.fc0(x) # 28*28 -> 30 \n",
    "        x = F.sigmoid(x) # Activation function \n",
    "        x = self.fc1(x)  # 30 -> 10, logit for each class\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_net = MNIST_Net()#.cuda() # create the neural network instance and load to the cuda memory.\n",
    "criterion = nn.CrossEntropyLoss() # Define Loss Function. We use Cross-Entropy loss.\n",
    "optimizer = optim.SGD(mnist_net.parameters(), lr=0.001) # optimizer receives training parameters and learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(trainloader = trainDataLoader,\n",
    "                  testloader = testDataLoader,\n",
    "                  net = mnist_net,\n",
    "                  criterion = criterion,\n",
    "                  optimizer = optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kwonsoonjae/opt/anaconda3/lib/python3.8/site-packages/torch/nn/functional.py:1639: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   500] loss: 2.327\n",
      "[1,  1000] loss: 2.297\n",
      "[1,  1500] loss: 2.277\n",
      "[2,   500] loss: 2.253\n",
      "[2,  1000] loss: 2.242\n",
      "[2,  1500] loss: 2.230\n",
      "[3,   500] loss: 2.208\n",
      "[3,  1000] loss: 2.194\n",
      "[3,  1500] loss: 2.182\n",
      "[4,   500] loss: 2.155\n",
      "[4,  1000] loss: 2.138\n",
      "[4,  1500] loss: 2.121\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "trainer.train(epoch = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set:  Accuracy: 5921/10000 (59%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainer.test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exp (2) 2-Layer Network + ReLU\n",
    "\n",
    "- Input: (28 * 28)\n",
    "- Hidden dimension: 30\n",
    "- Output dimension: 10\n",
    "- activation: relu\n",
    "- Optimizer: SGD\n",
    "- Loss: Cross-Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNIST_Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MNIST_Net, self).__init__() \n",
    "        # an affine operation: y = Wx + b\n",
    "        self.fc0 = nn.Linear(28*28,30)\n",
    "        self.fc1 = nn.Linear(30, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1,28*28) \n",
    "        x = self.fc0(x) # 28*28 -> 30 \n",
    "        x = F.relu(x) # Activation function\n",
    "        x = self.fc1(x)  # 30 -> 10\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_net = MNIST_Net()#.cuda() \n",
    "criterion = nn.CrossEntropyLoss() \n",
    "optimizer = optim.SGD(mnist_net.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(trainloader = trainDataLoader,\n",
    "                  testloader = testDataLoader,\n",
    "                  net = mnist_net,\n",
    "                  criterion = criterion,\n",
    "                  optimizer = optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   500] loss: 2.281\n",
      "[1,  1000] loss: 2.219\n",
      "[1,  1500] loss: 2.141\n",
      "[2,   500] loss: 1.952\n",
      "[2,  1000] loss: 1.821\n",
      "[2,  1500] loss: 1.672\n",
      "[3,   500] loss: 1.403\n",
      "[3,  1000] loss: 1.260\n",
      "[3,  1500] loss: 1.141\n",
      "[4,   500] loss: 0.973\n",
      "[4,  1000] loss: 0.905\n",
      "[4,  1500] loss: 0.848\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "trainer.train(epoch = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set:  Accuracy: 8336/10000 (83%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainer.test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 3) Is there any difference in performance according to the activiation function?\n",
    "\n",
    "ReLU가 Sigmoid에 비해 압도적으로 성능이 좋음!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exp (3) 3-Layer Network + Sigmoid\n",
    "\n",
    "- Input: (28 * 28)\n",
    "- Hidden dimension: (50, 30)\n",
    "- Output dimension: 10\n",
    "- activation: sigmoid\n",
    "- Optimizer: SGD\n",
    "- Loss: Cross-Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNIST_Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MNIST_Net, self).__init__()\n",
    "        self.fc0 = nn.Linear(28*28,50) # Layer 1\n",
    "        self.fc1 = nn.Linear(50, 30) # Layer 2\n",
    "        self.fc2 = nn.Linear(30, 10) # Layer 3\n",
    "\n",
    "    def forward(self, x):\n",
    "      \n",
    "        x = x.view(-1,28*28)\n",
    "        x = self.fc0(x)\n",
    "        x = F.sigmoid(x)\n",
    "        x = self.fc1(x)\n",
    "        x = F.sigmoid(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_net = MNIST_Net()#.cuda() \n",
    "criterion = nn.CrossEntropyLoss() \n",
    "optimizer = optim.SGD(mnist_net.parameters(), lr=0.001)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(trainloader = trainDataLoader,\n",
    "                  testloader = testDataLoader,\n",
    "                  net = mnist_net,\n",
    "                  criterion = criterion,\n",
    "                  optimizer = optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   500] loss: 2.309\n",
      "[1,  1000] loss: 2.304\n",
      "[1,  1500] loss: 2.302\n",
      "[2,   500] loss: 2.301\n",
      "[2,  1000] loss: 2.300\n",
      "[2,  1500] loss: 2.299\n",
      "[3,   500] loss: 2.299\n",
      "[3,  1000] loss: 2.299\n",
      "[3,  1500] loss: 2.298\n",
      "[4,   500] loss: 2.299\n",
      "[4,  1000] loss: 2.297\n",
      "[4,  1500] loss: 2.298\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "trainer.train(epoch = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set:  Accuracy: 1135/10000 (11%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainer.test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exp (4) 3-Layer Network + ReLU\n",
    "\n",
    "- Input: (28 * 28)\n",
    "- Hidden dimension: (50, 30)\n",
    "- Output dimension: 10\n",
    "- activation: relu\n",
    "- Optimizer: SGD\n",
    "- Loss: Cross-Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNIST_Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MNIST_Net, self).__init__()\n",
    "        self.fc0 = nn.Linear(28*28,50) # Layer 1\n",
    "        self.fc1 = nn.Linear(50, 30) # Layer 2\n",
    "        self.fc2 = nn.Linear(30, 10) # Layer 3\n",
    "\n",
    "    def forward(self, x):\n",
    "      \n",
    "        x = x.view(-1,28*28)\n",
    "        x = self.fc0(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_net = MNIST_Net()#.cuda() \n",
    "criterion = nn.CrossEntropyLoss() \n",
    "optimizer = optim.SGD(mnist_net.parameters(), lr=0.001) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(trainloader = trainDataLoader,\n",
    "                  testloader = testDataLoader,\n",
    "                  net = mnist_net,\n",
    "                  criterion = criterion,\n",
    "                  optimizer = optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   500] loss: 2.303\n",
      "[1,  1000] loss: 2.286\n",
      "[1,  1500] loss: 2.269\n",
      "[2,   500] loss: 2.226\n",
      "[2,  1000] loss: 2.190\n",
      "[2,  1500] loss: 2.144\n",
      "[3,   500] loss: 2.026\n",
      "[3,  1000] loss: 1.938\n",
      "[3,  1500] loss: 1.826\n",
      "[4,   500] loss: 1.602\n",
      "[4,  1000] loss: 1.463\n",
      "[4,  1500] loss: 1.325\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "trainer.train(epoch = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set:  Accuracy: 7339/10000 (73%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainer.test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 4) Is training gets done easily in experiment (3),(4) compared to experiment (1),(2)? If it doesn't, why not?\n",
    "\n",
    "- (3), (4)가 (1), (2)에 비해 시간도 더 오래 걸리고 성능도 더 안좋게 나옴\n",
    "- 이유는 일단 parameter가 더 많아서 연산 시간이 오래 걸리며, 성능은 잘 모르겠음 아직"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 5) What would happen if there is no activation function?\n",
    "- 선형 결합으로만 이루어지기 때문에 문제 발생 -> 어떤 문제인지는 좀더 찾아보자"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's Change our Optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Adam](./imgs/adam.jpeg)\n",
    "\n",
    "Reference: 하용호, 자습해도 모르겠던 딥러닝, 머리속에 인스톨 시켜드립니다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exp (5) 3-Layer Network + ReLU + Adam\n",
    "\n",
    "- Input: (28 * 28)\n",
    "- Hidden dimension: (50, 30)\n",
    "- Output dimension: 10\n",
    "- activation: relu\n",
    "- Optimizer: Adam\n",
    "- Loss: Cross-Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNIST_Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MNIST_Net, self).__init__()\n",
    "        self.fc0 = nn.Linear(28*28,50) # Layer 1\n",
    "        self.fc1 = nn.Linear(50, 30) # Layer 2\n",
    "        self.fc2 = nn.Linear(30, 10) # Layer 3\n",
    "\n",
    "    def forward(self, x):\n",
    "      \n",
    "        x = x.view(-1,28*28)\n",
    "        x = self.fc0(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_net = MNIST_Net()#.cuda() \n",
    "criterion = nn.CrossEntropyLoss()  \n",
    "optimizer = optim.Adam(mnist_net.parameters(), lr=0.001) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(trainloader = trainDataLoader,\n",
    "                  testloader = testDataLoader,\n",
    "                  net = mnist_net,\n",
    "                  criterion = criterion,\n",
    "                  optimizer = optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   500] loss: 0.650\n",
      "[1,  1000] loss: 0.313\n",
      "[1,  1500] loss: 0.252\n",
      "[2,   500] loss: 0.196\n",
      "[2,  1000] loss: 0.185\n",
      "[2,  1500] loss: 0.166\n",
      "[3,   500] loss: 0.134\n",
      "[3,  1000] loss: 0.136\n",
      "[3,  1500] loss: 0.132\n",
      "[4,   500] loss: 0.102\n",
      "[4,  1000] loss: 0.111\n",
      "[4,  1500] loss: 0.105\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "trainer.train(epoch = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set:  Accuracy: 9660/10000 (97%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainer.test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exp (6) 2-Layer Network + ReLU + Adam\n",
    "\n",
    "- Input: (28 * 28)\n",
    "- Hidden dimension: (30)\n",
    "- Output dimension: 10\n",
    "- activation: relu\n",
    "- Optimizer: Adam\n",
    "- Loss: Cross-Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNIST_Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MNIST_Net, self).__init__() \n",
    "        # an affine operation: y = Wx + b\n",
    "        self.fc0 = nn.Linear(28*28,30)\n",
    "        self.fc1 = nn.Linear(30, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1,28*28) \n",
    "        x = self.fc0(x) # 28*28 -> 30 \n",
    "        x = F.relu(x) \n",
    "        x = self.fc1(x) \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_net = MNIST_Net()#.cuda() \n",
    "criterion = nn.CrossEntropyLoss() \n",
    "optimizer = optim.Adam(mnist_net.parameters(), lr=0.001) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(trainloader = trainDataLoader,\n",
    "                  testloader = testDataLoader,\n",
    "                  net = mnist_net,\n",
    "                  criterion = criterion,\n",
    "                  optimizer = optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   500] loss: 0.680\n",
      "[1,  1000] loss: 0.311\n",
      "[1,  1500] loss: 0.289\n",
      "[2,   500] loss: 0.226\n",
      "[2,  1000] loss: 0.209\n",
      "[2,  1500] loss: 0.209\n",
      "[3,   500] loss: 0.175\n",
      "[3,  1000] loss: 0.167\n",
      "[3,  1500] loss: 0.156\n",
      "[4,   500] loss: 0.130\n",
      "[4,  1000] loss: 0.135\n",
      "[4,  1500] loss: 0.145\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "trainer.train(epoch = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set:  Accuracy: 9596/10000 (96%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainer.test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch-Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![normalization](./imgs/normalization.png)\n",
    "\n",
    "Reference: Andrew Ng, Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exp (7) 2-Layer Network + ReLU + Adam + Batch-Norm\n",
    "\n",
    "- Input: (28 * 28)\n",
    "- Hidden dimension: (30)\n",
    "- Output dimension: 10\n",
    "- activation: relu\n",
    "- normalization: batch-norm\n",
    "- Optimizer: Adam\n",
    "- Loss: Cross-Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNIST_Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MNIST_Net, self).__init__() \n",
    "        # an affine operation: y = Wx + b\n",
    "        self.fc0 = nn.Linear(28*28,30)\n",
    "        self.bn0 = nn.BatchNorm1d(30) # BatchNorm \n",
    "        self.fc1 = nn.Linear(30, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1,28*28) \n",
    "        x = self.fc0(x) # 28*28 -> 30 \n",
    "        x = self.bn0(x)\n",
    "        x = F.relu(x) \n",
    "        x = self.fc1(x)   \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_net = MNIST_Net()#.cuda() \n",
    "criterion = nn.CrossEntropyLoss() \n",
    "optimizer = optim.Adam(mnist_net.parameters(), lr=0.001)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(trainloader = trainDataLoader,\n",
    "                  testloader = testDataLoader,\n",
    "                  net = mnist_net,\n",
    "                  criterion = criterion,\n",
    "                  optimizer = optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   500] loss: 0.713\n",
      "[1,  1000] loss: 0.346\n",
      "[1,  1500] loss: 0.282\n",
      "[2,   500] loss: 0.225\n",
      "[2,  1000] loss: 0.209\n",
      "[2,  1500] loss: 0.204\n",
      "[3,   500] loss: 0.168\n",
      "[3,  1000] loss: 0.171\n",
      "[3,  1500] loss: 0.164\n",
      "[4,   500] loss: 0.150\n",
      "[4,  1000] loss: 0.147\n",
      "[4,  1500] loss: 0.141\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "trainer.train(epoch = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set:  Accuracy: 9628/10000 (96%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainer.test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exp (8) 3-Layer Network + ReLU + Adam + Batch-Norm\n",
    "\n",
    "- Input: (28 * 28)\n",
    "- Hidden dimension: (50, 30)\n",
    "- Output dimension: 10\n",
    "- activation: relu\n",
    "- normalization: batch-norm\n",
    "- Optimizer: Adam\n",
    "- Loss: Cross-Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNIST_Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MNIST_Net, self).__init__()\n",
    "        self.fc0 = nn.Linear(28*28,50) # Layer 1\n",
    "        self.bn0 = nn.BatchNorm1d(50) # BatchNorm 1 \n",
    "        self.fc1 = nn.Linear(50, 30) # Layer 2\n",
    "        self.bn1 = nn.BatchNorm1d(30) # BatchNorm 2\n",
    "        self.fc2 = nn.Linear(30, 10) # Layer 3\n",
    "\n",
    "    def forward(self, x):\n",
    "      \n",
    "        x = x.view(-1,28*28)\n",
    "        x = self.fc0(x)\n",
    "        x = self.bn0(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_net = MNIST_Net()#.cuda() \n",
    "criterion = nn.CrossEntropyLoss() \n",
    "optimizer = optim.Adam(mnist_net.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(trainloader = trainDataLoader,\n",
    "                  testloader = testDataLoader,\n",
    "                  net = mnist_net,\n",
    "                  criterion = criterion,\n",
    "                  optimizer = optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   500] loss: 0.639\n",
      "[1,  1000] loss: 0.259\n",
      "[1,  1500] loss: 0.215\n",
      "[2,   500] loss: 0.150\n",
      "[2,  1000] loss: 0.143\n",
      "[2,  1500] loss: 0.140\n",
      "[3,   500] loss: 0.111\n",
      "[3,  1000] loss: 0.122\n",
      "[3,  1500] loss: 0.119\n",
      "[4,   500] loss: 0.088\n",
      "[4,  1000] loss: 0.102\n",
      "[4,  1500] loss: 0.100\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "trainer.train(epoch = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set:  Accuracy: 9753/10000 (98%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainer.test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 6) Is there any performance difference before/after applying the batch-norm?\n",
    "- Batch-norm 하니까 test accuracy가 1% 가량 더 좋아짐!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HW 1.1 Let's Do It: Let's achieve performance greater than 97%!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNIST_Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MNIST_Net, self).__init__()\n",
    "        self.fc0 = nn.Linear(28*28, 60) # Layer 1\n",
    "        self.bn0 = nn.BatchNorm1d(60) # BatchNorm 1 \n",
    "        self.fc1 = nn.Linear(60, 40) # Layer 2\n",
    "        self.bn1 = nn.BatchNorm1d(40) # BatchNorm 2\n",
    "        self.fc2 = nn.Linear(40, 20) # Layer 3\n",
    "        self.bn2 = nn.BatchNorm1d(20) # BatchNorm 3\n",
    "        self.fc3 = nn.Linear(20, 10) # Layer 4\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.xavier_init()\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = x.view(-1,28*28)\n",
    "        x = self.fc0(x)\n",
    "        x = self.bn0(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = self.fc1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = self.fc2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def xavier_init(self):\n",
    "        nn.init.xavier_normal_(self.fc0.weight)\n",
    "        nn.init.xavier_normal_(self.fc1.weight)\n",
    "        nn.init.xavier_normal_(self.fc2.weight)\n",
    "        nn.init.xavier_normal_(self.fc3.weight)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_net = MNIST_Net()#.cuda() \n",
    "criterion = nn.CrossEntropyLoss()  \n",
    "optimizer = optim.Adam(mnist_net.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(trainloader = trainDataLoader,\n",
    "                  testloader = testDataLoader,\n",
    "                  net = mnist_net,\n",
    "                  criterion = criterion,\n",
    "                  optimizer = optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   500] loss: 0.959\n",
      "[1,  1000] loss: 0.447\n",
      "[1,  1500] loss: 0.366\n",
      "[2,   500] loss: 0.297\n",
      "[2,  1000] loss: 0.300\n",
      "[2,  1500] loss: 0.273\n",
      "[3,   500] loss: 0.239\n",
      "[3,  1000] loss: 0.232\n",
      "[3,  1500] loss: 0.237\n",
      "[4,   500] loss: 0.204\n",
      "[4,  1000] loss: 0.209\n",
      "[4,  1500] loss: 0.206\n",
      "[5,   500] loss: 0.184\n",
      "[5,  1000] loss: 0.190\n",
      "[5,  1500] loss: 0.187\n",
      "[6,   500] loss: 0.173\n",
      "[6,  1000] loss: 0.175\n",
      "[6,  1500] loss: 0.185\n",
      "[7,   500] loss: 0.163\n",
      "[7,  1000] loss: 0.179\n",
      "[7,  1500] loss: 0.158\n",
      "[8,   500] loss: 0.161\n",
      "[8,  1000] loss: 0.163\n",
      "[8,  1500] loss: 0.161\n",
      "[9,   500] loss: 0.154\n",
      "[9,  1000] loss: 0.161\n",
      "[9,  1500] loss: 0.153\n",
      "[10,   500] loss: 0.147\n",
      "[10,  1000] loss: 0.154\n",
      "[10,  1500] loss: 0.148\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "trainer.train(epoch = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set:  Accuracy: 9751/10000 (98%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainer.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41250"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "count_parameters(mnist_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cf_matrix(model, test_loader=testDataLoader):\n",
    "    nb_classes = 10\n",
    "    confusion_matrix = np.zeros((nb_classes, nb_classes))\n",
    "    with torch.no_grad():\n",
    "        for i, (inputs, classes) in enumerate(test_loader):\n",
    "            #inputs = inputs.to(DEVICE)\n",
    "            #classes = classes.to(DEVICE)\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            for t, p in zip(classes.view(-1), preds.view(-1)):\n",
    "                    confusion_matrix[t.long(), p.long()] += 1\n",
    "\n",
    "    plt.figure(figsize=(15,10))\n",
    "\n",
    "    #class_names = list(label2class.values())\n",
    "    df_cm = pd.DataFrame(confusion_matrix).astype(int)\n",
    "    heatmap = sns.heatmap(df_cm, annot=True, fmt=\"d\")\n",
    "\n",
    "    heatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, ha='right',fontsize=15)\n",
    "    heatmap.xaxis.set_ticklabels(heatmap.xaxis.get_ticklabels(), rotation=0, ha='center',fontsize=15)\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cf_matrix(model=mnist_net, test_loader=testDataLoader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 7) What may be the potential problems when training the neural network with a large number of parameters?\n",
    "- overfitting 가능성이 큼\n",
    "- training time & computation cost가 큼"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's use Convolution Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolution Operation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Convolution](./imgs/Conv.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 8) Given input image with shape:(H, W, C1), what would be the shape of output image after applying 2 (F * F) convolutional filters with stride S?\n",
    "- ((H-F)/S + 1, (W-F)/S + 1, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (9) 3-Layer Network (Conv+Fc) + ReLU + Adam + Batch-Norm\n",
    "\n",
    "- Input: (28 * 28)\n",
    "- Conv: 8 (6 * 6) filter with stride=2 \n",
    "- Hidden dimension: 8 * 12 * 12\n",
    "- Output dimension: 10\n",
    "- activation: relu\n",
    "- normalization: batch-norm\n",
    "- Optimizer: Adam\n",
    "- Loss: Cross-Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNIST_Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MNIST_Net, self).__init__()\n",
    "        self.conv0 = nn.Conv2d(in_channels = 1,\n",
    "                               out_channels = 8,\n",
    "                               kernel_size = 6,\n",
    "                               stride = 2) # Layer 1\n",
    "        self.conv0_bn = nn.BatchNorm2d(8)  # 2d batch-norm is used in 3d inputs\n",
    "        self.fc = nn.Linear(8*12*12, 10)   # Layer 2 \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv0(x)\n",
    "        x = self.conv0_bn(x)\n",
    "        x = F.relu(x)\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_net = MNIST_Net()#.cuda() \n",
    "criterion = nn.CrossEntropyLoss() \n",
    "optimizer = optim.Adam(mnist_net.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(trainloader = trainDataLoader,\n",
    "                  testloader = testDataLoader,\n",
    "                  net = mnist_net,\n",
    "                  criterion = criterion,\n",
    "                  optimizer = optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   500] loss: 0.399\n",
      "[1,  1000] loss: 0.170\n",
      "[1,  1500] loss: 0.125\n",
      "[2,   500] loss: 0.080\n",
      "[2,  1000] loss: 0.082\n",
      "[2,  1500] loss: 0.083\n",
      "[3,   500] loss: 0.056\n",
      "[3,  1000] loss: 0.062\n",
      "[3,  1500] loss: 0.066\n",
      "[4,   500] loss: 0.051\n",
      "[4,  1000] loss: 0.052\n",
      "[4,  1500] loss: 0.052\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "trainer.train(epoch = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set:  Accuracy: 9832/10000 (98%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainer.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11842"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_parameters(mnist_net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 9) How did the performance and the number of parameters change after using the Convolution operation? Why did these results come out?\n",
    "- 성능은 좋아지고 parameter 수는 적어짐\n",
    "- 이는 convloution operation이 2D image의 local 정보를 보존할 수 있기 때문 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (10) 3-Layer Network (Conv+Pool+Fc) + ReLU + Adam + Batch-Norm\n",
    "\n",
    "- Input: (28 * 28)\n",
    "- Conv: 8 (7 * 7) filter with stride=2 \n",
    "- Pool: 2 * 2\n",
    "- Hidden dimension: 8 * 6 * 6\n",
    "- Output dimension: 10\n",
    "- activation: relu\n",
    "- normalization: batch-norm\n",
    "- Optimizer: Adam\n",
    "- Loss: Cross-Entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pooling Operation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Pooling](./imgs/Pool.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNIST_Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MNIST_Net, self).__init__()\n",
    "        self.conv0 = nn.Conv2d(in_channels = 1,\n",
    "                               out_channels = 8,\n",
    "                               kernel_size = 6,\n",
    "                               stride = 2) # Layer 1\n",
    "        self.conv0_bn = nn.BatchNorm2d(8)  \n",
    "        self.pool0 = nn.MaxPool2d(2)\n",
    "        self.fc = nn.Linear(8*6*6, 10) \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv0(x)\n",
    "        x = self.conv0_bn(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool0(x)\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_net = MNIST_Net()#.cuda() \n",
    "criterion = nn.CrossEntropyLoss()  \n",
    "optimizer = optim.Adam(mnist_net.parameters(), lr=0.001) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(trainloader = trainDataLoader,\n",
    "                  testloader = testDataLoader,\n",
    "                  net = mnist_net,\n",
    "                  criterion = criterion,\n",
    "                  optimizer = optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   500] loss: 0.545\n",
      "[1,  1000] loss: 0.203\n",
      "[1,  1500] loss: 0.155\n",
      "[2,   500] loss: 0.118\n",
      "[2,  1000] loss: 0.105\n",
      "[2,  1500] loss: 0.097\n",
      "[3,   500] loss: 0.085\n",
      "[3,  1000] loss: 0.080\n",
      "[3,  1500] loss: 0.080\n",
      "[4,   500] loss: 0.069\n",
      "[4,  1000] loss: 0.074\n",
      "[4,  1500] loss: 0.072\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "trainer.train(epoch = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set:  Accuracy: 9789/10000 (98%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainer.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3202"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_parameters(mnist_net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 10) How did the performance change after using the Pooling operation? Why did these results come out?\n",
    "- accuracy는 0.5% 정도 감소했지만 대신 parameter 수가 1/4로 줄어듦\n",
    "- Pooling layer를 거치면 정보의 손실을 감수하는 대신 computational cost를 줄일 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
